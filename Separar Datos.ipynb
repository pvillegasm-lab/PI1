{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97750fde",
   "metadata": {
    "id": "97750fde",
    "outputId": "c2db51d4-d81f-41c8-a315-195041075f3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Guardado: ./Processed Data1/AAPL.csv\n",
      "âœ… Guardado: ./Processed Data1/AMZN.csv\n",
      "âœ… Guardado: ./Processed Data1/GOOGL.csv\n",
      "âœ… Guardado: ./Processed Data1/META.csv\n",
      "âœ… Guardado: ./Processed Data1/MSFT.csv\n",
      "âœ… Guardado: ./Processed Data1/NVDA.csv\n",
      "âœ… Guardado: ./Processed Data1/TSLA.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ğŸ“¥ Ruta del CSV de entrada\n",
    "ARCHIVO_CSV = './Raw Data/stock_data_PI1.csv'\n",
    "\n",
    "# ğŸ“ Carpeta de salida\n",
    "CARPETA_SALIDA = './Processed Data1/'\n",
    "os.makedirs(CARPETA_SALIDA, exist_ok=True)\n",
    "\n",
    "# ğŸ“Š Leer el CSV\n",
    "df = pd.read_csv(ARCHIVO_CSV)\n",
    "\n",
    "# ğŸ§¹ Eliminar columna 'date'\n",
    "df = df.drop(columns=['date'])\n",
    "\n",
    "# ğŸ” Procesar cada ticker\n",
    "for ticker in df['ticker'].unique():\n",
    "    df_ticker = df[df['ticker'] == ticker].copy()\n",
    "    df_ticker = df_ticker.drop(columns=['ticker'])        # Eliminar columna 'ticker'\n",
    "    df_ticker.set_index('timestamp', inplace=True)        # Usar timestamp como Ã­ndice\n",
    "    df_ticker.sort_index(inplace=True)                    # Ordenar por timestamp ascendente\n",
    "\n",
    "    # ğŸ’¾ Guardar CSV por ticker\n",
    "    output_path = os.path.join(CARPETA_SALIDA, f'{ticker}.csv')\n",
    "    df_ticker.to_csv(output_path)\n",
    "    print(f\"âœ… Guardado: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd3c4c6",
   "metadata": {
    "id": "7dd3c4c6",
    "outputId": "2255adc7-1694-449c-ae28-1b1a8eaa0773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ VERIFICACIÃ“N DE NaN EN ARCHIVOS CSV\n",
      "\n",
      "âœ… AAPL.csv: SIN NaN\n",
      "âœ… AMZN.csv: SIN NaN\n",
      "âœ… GOOGL.csv: SIN NaN\n",
      "âœ… META.csv: SIN NaN\n",
      "âœ… MSFT.csv: SIN NaN\n",
      "âœ… NVDA.csv: SIN NaN\n",
      "âœ… TSLA.csv: SIN NaN\n"
     ]
    }
   ],
   "source": [
    "#Verificar si los CSV tienen NaN\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ğŸ“ Carpeta con los archivos CSV que quieres revisar\n",
    "CARPETA = './Processed Data1/'  # Cambia esto segÃºn tu ruta\n",
    "\n",
    "# ğŸ” Verificar cada archivo CSV\n",
    "def verificar_nans_en_csvs(carpeta):\n",
    "    archivos = [f for f in os.listdir(carpeta) if f.endswith('.csv')]\n",
    "\n",
    "    print(\"\\nğŸ“‹ VERIFICACIÃ“N DE NaN EN ARCHIVOS CSV\\n\")\n",
    "\n",
    "    for archivo in archivos:\n",
    "        ruta = os.path.join(carpeta, archivo)\n",
    "        df = pd.read_csv(ruta)\n",
    "        total_nans = df.isna().sum().sum()\n",
    "\n",
    "        if total_nans == 0:\n",
    "            print(f\"âœ… {archivo}: SIN NaN\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ {archivo}: {total_nans} valores NaN encontrados\")\n",
    "\n",
    "# ğŸ Ejecutar\n",
    "verificar_nans_en_csvs(CARPETA)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
